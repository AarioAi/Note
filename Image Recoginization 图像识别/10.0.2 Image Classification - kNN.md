# Image Classification Pipeline

http://cs231n.github.io

> Keywords:
>> **L1/L2 distances**, **hyperparameter search**, **cross-validation**

Nearest Neighbor Classifier has nothing to do with Convolutional Neural Networks, and it's very rarely used in practice.

* Pros:
  * a good choice when the data is low-dimensional
* Cons:
  * not suit for high-dimensional spaces
  * must remember all training data --> inefficient
  * requires a comparion to all training images to classify a test image

![L2 distance](http://cs231n.github.io/assets/samenorm.png)

**Summary 总结**
* **Image Classification** 监督学习标注后的图像集，去预测
* **Nearest Neighbor Classifier** there're multiple **hyper-parameters** (such as value of k, or the type of distance used to compare examples)
* Set these hyperparameters: split training data into two: a training set and a **validation set**.
* **cross-validation** can help reduce noise in estimating which hyperparameters work best
* **evaluation** on the actual **test set**
* L1/L2 distances is not adequate


### L1 Distance

One of the simplest possibilities is to compare the images pixel by pixel and add up all the differences.

$d_1(I_1,I_2) = \sum_p{|I_1^p - I_2^p|}$

Pixel-wise differences to compare two images with L1 distance (for one color channel)

```flow
 test image     training image     d1
  [56,32]         [10,20]        [46,12]
  [90,23]    -    [ 8,10]   =    [82,13]   =  153
```

### L2 Distance

L2 distance has the geometric interpretation of computing the euclidean distance between two vectors.

$d_2(I_1,I_2) = \sqrt{\sum_p(I_1^p - I_2^p)^2}$

## kNN

 Instead of finding the single closest image in the training set, we will find the top k closest images, and have them vote on the label of the test image. In particular, when k = 1, we recover the Nearest Neighbor classifier. Intuitively, higher values of k have a smoothing effect that makes the classifier more resistant to outliers:

 ![kNN](http://cs231n.github.io/assets/knn.jpeg)

> **Hyperparameters**: We saw that there are many different distance functions we could have used: L1 norm, L2 norm, there are many other choices we didn’t even consider (e.g. dot products). These choices are called hyperparameters.
>> Do not the test set for the purpose of tweaking hyperparameters.
>>> Evaluate on the test set only a single time, at the very end.
>> Split your training set into training set (ps: 49,000 out of a 50,000 images training set) and a **validation set** (ps: 1000 out of a 50,000 images training set). Use validation set to tune all hyperparameters. At the end run a single time on the test set and report performance.

```psucode
accuries = []
for k in [1, 3, 5, 10, 20, 50, 100] {
  nn = NearestNeighbor()
  nn.train(last49000forTrainX, last49000forTrainY)
  predict = nn.predict(first1000forValidationX, k)
  accuracy = np.mean(predict == first1000forValidationY)
  accuries[k] = accuracy
}
```

>> **Cross-validation**
