# YOLOv3

## Intro

### Bounding Box Prediction

![Bounding Box Prediction](https://github.com/AarioAi/Note/blob/master/Image%20Recoginization%20%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/_asset/YOLOv3-bounding-box.jpg?raw=true)

The network predicts 4 coordinates for each bounding box, $t_x$, $t_y$, $t_w$, $t_h$. If the cell is offset from the top left corner of the image by ($c_x$, $c_y$) and the bounding box prior has width and height $p_w$, $p_h$.


YOLOv3 predicts an objectness score for each bounding box using **logistic regression**. This should be 1 if the bounding box prior overlaps a ground truth object by more than any other bounding box prior. If the bounding box prior is not the best but does overlap a ground truth object by more than some threshold we ignore the prediction, following. We use the threshold of .5.

### Class Prediction

YOLOv3 uses multi-label classification. For example, the output labels may be “pedestrian” and “child” which are not non-exclusive. (the sum of output can be greater than 1 now. Therefore, YOLO (which refers to YOLOv1) applies a softmax function to convert scores into probabilities that sum up to one. ).

YOLOv3 replaces the **softmax** function with independent logistic classifiers to calculate the likeliness of the input belongs to a specific label. 

 Instead of using **mean square error** in calculating the classification loss, YOLOv3 uses **binary cross-entropy loss** for each label. This also reduces the computation complexity by avoiding the softmax function.


> Using a softmax imposes the assumption that each box has exactly one class which is often not the case.



### Network Design


## Inference: Non-maximal Suppression

YOLO can make duplicate detections for the same object. Here is one of the possible non-maximal suppression implementation:

```
boundingBoxes=[(x,y,w,h,confidenceScore)...]
sortDescByConfidenceScore(&boundingBoxes)
uniqueDetections=[]
uniqueDetections[] = boundingBoxes[0]
for i=1;i<len(boundingBoxes); i++{
    if IoU(boundingBoxes[i], boundingBoxes[i-1]) <= 0.5 {
        uniqueDetections[] = IoU(boundingBoxes[i]

    }
}
```
1. sort the predictions by the confidence scores
2. start from the top score, ignore any current prediction if we find any previous predictions that have the same class and IoU $\gt$ 0.5 with the current prediction.
3. repeat s


## YOLO and YOLOv2

### Grid Cell
For our discussion, we crop our original photo. YOLO divides the input image into an S×S grid. Each grid cell predicts only one object. For example, the yellow grid cell below tries to predict the “person” object whose center (the blue dot) falls inside the grid cell.

![Each grid cell detects one object for our discussion](https://github.com/AarioAi/Note/blob/master/Image%20Recoginization%20%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/_asset/YOLOv3-grid-cell.jpg?raw=true)

Each grid cell predicts a fixed number of boundary boxes. In this example, the yellow grid cell makes two boundary box predictions (blue boxes) to locate where the person is.

![A grid makes two boundary-boxes for our discussion](https://github.com/AarioAi/Note/blob/master/Image%20Recoginization%20%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/_asset/YOLOv3-grid-bounding-box.jpg?raw=true)


For each grid cell,

* it predicts B boundary boxes and each box has one **box confidence score**,
* it detects one object only regardless of the number of boxes B,
* it predicts C **conditional class probabilities** (one per class for the likeliness of the object class).
  
> To evaluate PASCAL VOC, YOLO uses 7×7 grids (S×S), 2 boundary boxes (B) and 20 classes (C, Each cell has 20 conditional class probabilities. ).

![YOYO make SxS predictions with B boundary boxes.](https://github.com/AarioAi/Note/blob/master/Image%20Recoginization%20%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/_asset/YOLOv3-make-SxS-predictions.jpg?raw=true)



**Each boundary box contains 5 elements: (x, y, w, h) and a box confidence score**. The confidence score reflects how likely the box contains an object (**objectness**) and how accurate is the boundary box.

The **conditional class probability** is the probability that the detected object belongs to a particular class (one probability per category for each cell).


* box confidence score $\equiv$ $P_r(obj) * IoU$
  * $P_r(obj)$ is the probability the box contains an object
* conditional class probability $\equiv$ $P_r(class_i|obj)
  * $P_r(class_i|obj) is the probability the object belongs to $class_i$ given an object is presense.
* class confidence score $\equiv$ $P_r(class_i) * IoU = box * confidence score * conditional class probability
  * $P_r(class_i)$ is the probability the object belongs to $class_i$


### Loss Function
YOLO predicts multiple bounding boxes per grid cell. YOLO uses sum-squared error between the predictions and the ground truth to calculate loss. The loss function composes of: the **classification loss**, the **localization loss** (errors between the predicted boundary box and the ground truth), the **confidence loss** (the objectness of the box).



## Reference
* https://pjreddie.com/media/files/papers/YOLOv3.pdf
* https://medium.com/@jonathan_hui/real-time-object-detection-with-yolo-yolov2-28b1b93e2088