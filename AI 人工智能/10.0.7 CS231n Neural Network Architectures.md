# Neural Network Architectures

## Layer-wise Organization

**Fully-connected layer** in which neurons between two adjacent layers are fully pairwise connected, but neurons within a single layer share no connections.

![Fully Connected Neural Network](https://github.com/AarioAi/Note/blob/master/AI%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/_asset/CS231n-fully-connected-neural-network.jpg?raw=true)

> Naming conventions:
    >> Notice that when we say N-layer neural network, we do not count the input layer. Therefore, a single-layer neural network describes a network with no hidden layers (input directly mapped to output). In that sense, you can sometimes hear people say that logistic regression or SVMs are simply a special case of single-layer Neural Networks. You may also hear these networks interchangeably referred to as “Artificial Neural Networks” (ANN) or “Multi-Layer Perceptrons” (MLP). Many people do not like the analogies between Neural Networks and real brains and prefer to refer to neurons as units.
>
> Sizing neural networks:
    >> The two metrics that people commonly use to measure the size of neural networks are the number of neurons, or more commonly the number of parameters. Working with the two example networks in the above picture: (1) The first network has $4+2=6$ neurons, $(3*4)+(4*2)=20$ weights and $4+2=6$ biases, for a total of 26 learnable parameters. (2) The second network has $4+4+1=9$ neurons, $(3*4)+(4*4)+(4*1)=32$ weights and $4+4+1=9$ biases, for a total of 41 learnable parameters.
    >>
    >> Modern convolutional networks contain on orders of 100 million parameters and are usually made up of approximately 10 to 20 layers (hence deep-learning).

![Fully Connected Layer v.s. Convolutional Layer](https://github.com/AarioAi/Note/blob/master/AI%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/_asset/CS231n-fully-connected-vs-convolutional-layers.png?raw=true)

![CNN Layers](https://github.com/AarioAi/Note/blob/master/AI%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/_asset/CS231n-CNN-layers.jpg?raw=true)


