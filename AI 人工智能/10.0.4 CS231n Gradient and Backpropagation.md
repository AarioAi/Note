# CS231n Gradient Descent

## Gradient Descent and Learning Rate

$$f(x) = kx + b \rightarrow  k = \frac{{\delta}f(x)}{{\delta}x} = lim_{h->0}\frac{f(x+h) - f(x)}{h}$$

$$f(x,y)=xy  \rightarrow  \frac{{\delta}f}{{\delta}x} = y,  \frac{{\delta}f}{{\delta}x} = x$$

$$ gradient: \frac{d(fx)}{dx} = lim_{h->0}\frac{f(x+h)-f(x)}{h}$$

> $$f(x) = \frac{1}{x}  \rightarrow \frac{{\delta}f(x)}{{\delta}x} = -\frac{1}{x^2}$$
> $$f(x) = e^x \rightarrow \frac{{\delta}f(x)}{{\delta}x}  = e^x$$

![Gradient Demo](https://github.com/AarioAi/Note/blob/master/AI%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/_asset/CS231n-gradient-demo.jpg?raw=true)

$$f(x = -2, y = 5, z = -4) = (x+y) * z$$

$$q=x+y = 1x + y = 1y + x \rightarrow \frac{{\delta}q}{{\delta}x} =  \frac{{\delta}q}{{\delta}y} = 1$$

$$f=qz \rightarrow \frac{{\delta}f}{{\delta}q} = z; \frac{{\delta}f}{{\delta}z} = q$$

The **chain rule** tells us that the correct way to “chain” these gradient expressions together is through multiplication. E.g., $\frac{{\delta}f}{{\delta}x} = \frac{{\delta}f}{{\delta}q} * \frac{{\delta}q}{{\delta}x}$

At the end we are left with the gradient in the variables [$\frac{{\delta}f}{{\delta}x}$, $\frac{{\delta}f}{{\delta}y}$, $\frac{{\delta}f}{{\delta}z}$], which tell us the sensitivity of the variables x,y,z on f!. This is the simplest example of **backpropagation**.

> $\frac{{\delta}f}{{\delta}x} = -4$ if x were to descrease (responding to their negative gradient) then the add gate's output q would decrease, which inturn makes the multiply gate's output f increase.
>> Backpropagation can thus be thought of as gates communicating to each other (through the gradient signal) whether they want their outputs to increase or decrease (and how strongly), so as to make the final output value higher.

### Intuitive understanding of backpropagation

Every gate in a circuit diagram gets some inputs and can right away compute two things: 1. its output value and 2. the local gradient of its inputs with respect to its output value. Chain rule says that the gate should take that gradient and multiply it into every gradient it normally computes for all of its inputs.

> This extra multiplication (for each input) due to the chain rule can turn a single and relatively useless gate into a cog in a complex circuit such as an entire neural network.

### Modularity: Sigmoid activation function

Sigmoid Function $\sigma$:

$$\sigma(x) = \frac{1}{1 + e^{-x}}$$

$$\rightarrow \frac{d\sigma(x)}{dx} = \frac{e^{-x}}{(1+e^{-x})^2} = (\frac{1 + e^{-x} - 1}{1 + e^{-x}})(\frac{1}{1+e^{-x}}) = (1 - \sigma(x))\sigma(x)$$

![modularity signmoid](https://github.com/AarioAi/Note/blob/master/AI%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/_asset/CS231n-modularity-sigmoid.jpg?raw=true)

Example circuit for a 2D neuron with a sigmoid activation function. The inputs are x0,x1 and the (learnable) weights of the neuron are w0,w1,w2. As we will see later, the neuron computes a dot product with the input and then its activation is softly squashed by the sigmoid function to be in range from 0 to 1.

In the example above, we see a long chain of function applications that operates on the result of the dot product between w,x. The function that these operations implement is called the **sigmoid function σ(x)**.

```python
w = [2,-3,-3] # assume some random weights and data
x = [-1, -2]

# forward pass
dot = w[0]*x[0] + w[1]*x[1] + w[2]
f = 1.0 / (1 + math.exp(-dot)) # sigmoid function

# backward pass through the neuron (backpropagation)
ddot = (1 - f) * f # gradient on dot variable, using the sigmoid gradient derivation
dx = [w[0] * ddot, w[1] * ddot] # backprop into x
dw = [x[0] * ddot, x[1] * ddot, 1.0 * ddot] # backprop into w
# we're done! we have the gradients on the inputs to the circuit
```

![Gradient](https://github.com/AarioAi/Note/blob/master/AI%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/_asset/CS231n-gradient.jpg?raw=true)

* numerical gradient: approximate, slow, easy to write
* analytic gradient: exact, fast, error-prone
  
> **Gradient Check**: in practice,  always use analystic gradient, but check implementation with numerical gradient.
> Only use a small portion of the training set to compute the gradient. Common mini-batch sizes are 32/64/128/256 examples.

```python
while True:
    data_batch = sample_training_data(data, 256)    # sample 256 examples
    weights_grad = evaluate_gradient(loss_fun, data, weights)
    weights += -learning_rate * weight_grad    #  learning_rate is also called step_size
```

![The effects of learning rate](https://github.com/AarioAi/Note/blob/master/AI%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/_asset/CS231n-the-effects-of-learning-rate.jpg?raw=true)

## Reference
* http://cs231n.github.io/linear-classify/
* http://vision.stanford.edu/teaching/cs231n-demos/linear-classify/