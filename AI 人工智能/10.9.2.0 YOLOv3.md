# YOLOv3

## Intro

### Bounding Box Prediction

![Bounding Box Prediction](https://github.com/AarioAi/Note/blob/master/AI%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/_asset/YOLOv3-bounding-box.jpg?raw=true)

The network predicts 4 coordinates for each bounding box, $t_x$, $t_y$, $t_w$, $t_h$. If the cell is offset from the top left corner of the image by ($c_x$, $c_y$) and the bounding box prior has width and height $p_w$, $p_h$.


YOLOv3 predicts an objectness score for each bounding box using **logistic regression**. This should be 1 if the bounding box prior overlaps a ground truth object by more than any other bounding box prior. If the bounding box prior is not the best but does overlap a ground truth object by more than some threshold we ignore the prediction, following. We use the threshold of .5.

### Class Prediction

YOLOv3 uses multi-label classification. For example, the output labels may be “pedestrian” and “child” which are not non-exclusive. (the sum of output can be greater than 1 now. Therefore, YOLO (which refers to YOLOv1) applies a softmax function to convert scores into probabilities that sum up to one. ).

YOLOv3 replaces the **softmax** function with independent logistic classifiers to calculate the likeliness of the input belongs to a specific label. 

 Instead of using **mean square error** in calculating the classification loss, YOLOv3 uses **binary cross-entropy loss** for each label. This also reduces the computation complexity by avoiding the softmax function.

> Using a softmax imposes the assumption that each box has exactly one class which is often not the case.

### Network Design

#### FPN (Feature Pyramid Networks)

YOLOv3 makes 3 predictions per location. Each prediction composes of a boundary box, an objectness and 80 class scores, i.e. $N × N × [3 × (4 + 1 + 80) ]$ predictions.

```ini
; darknet.cfg
[convolutional]
filters=66          ; 66 = 3 * (4 + 1 + 17)

[yolo]
mask = 0,1,2

; COCO anchors
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326


classes=17
```

To determine the priors, YOLOv3 applies k-means cluster. Then it pre-select 9 clusters. For COCO, the width and height of the anchors are (10×13),(16×30),(33×23),(30×61),(62×45),(59× 119),(116 × 90),(156 × 198),(373 × 326). These 9 priors are grouped into 3 different groups according to their scale. Each group is assigned to a specific feature map above in detecting objects.

### Feature Extractor and Performance

Darknet-53 has less BFLOP (billion floating point operations) than ResNet-152, but achieves the same classification accuracy at 2x faster.

![Darknet-53](https://github.com/AarioAi/Note/blob/master/AI%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/_asset/YOLOv3-darknet-53.png?raw=true)

> 320 x 320 YOLOv3's COCO AP metric is on par with SSD but 3x faster.

![YOLOv3 Performace](https://github.com/AarioAi/Note/blob/master/AI%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/_asset/YOLOv3-performace.png?raw=true)




## Inference: Non-maximal Suppression

YOLO can make duplicate detections for the same object. Here is one of the possible non-maximal suppression implementation:

```
boundingBoxes=[(x,y,w,h,confidenceScore)...]
sortDescByConfidenceScore(&boundingBoxes)
uniqueDetections=[]
uniqueDetections[] = boundingBoxes[0]
for i=1;i<len(boundingBoxes); i++{
    if IoU(boundingBoxes[i], boundingBoxes[i-1]) <= 0.5 {
        uniqueDetections[] = IoU(boundingBoxes[i]

    }
}
```

1. sort the predictions by the confidence scores
2. start from the top score, ignore any current prediction if we find any previous predictions that have the same class and IoU $\gt$ 0.5 with the current prediction.
3. repeat s





## YOLO and YOLOv2

### Grid Cell
For our discussion, we crop our original photo. YOLO divides the input image into an S×S grid. Each grid cell predicts only one object. For example, the yellow grid cell below tries to predict the “person” object whose center (the blue dot) falls inside the grid cell.

![Each grid cell detects one object for our discussion](https://github.com/AarioAi/Note/blob/master/AI%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/_asset/YOLOv3-grid-cell.jpg?raw=true)

Each grid cell predicts a fixed number of boundary boxes. In this example, the yellow grid cell makes two boundary box predictions (blue boxes) to locate where the person is.

![A grid makes two boundary-boxes for our discussion](https://github.com/AarioAi/Note/blob/master/AI%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/_asset/YOLOv3-grid-bounding-box.jpg?raw=true)


For each grid cell,

* it predicts B boundary boxes and each box has one **box confidence score**,
* it detects one object only regardless of the number of boxes B,
* it predicts C **conditional class probabilities** (one per class for the likeliness of the object class).
  
> To evaluate PASCAL VOC, YOLO uses 7×7 grids (S×S), 2 boundary boxes (B) and 20 classes (C, Each cell has 20 conditional class probabilities. ).

![YOYO make SxS predictions with B boundary boxes.](https://github.com/AarioAi/Note/blob/master/AI%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/_asset/YOLOv3-make-SxS-predictions.jpg?raw=true)



**Each boundary box contains 5 elements: (x, y, w, h) and a box confidence score**. The confidence score reflects how likely the box contains an object (**objectness**) and how accurate is the boundary box.

The **conditional class probability** is the probability that the detected object belongs to a particular class (one probability per category for each cell).


* box confidence score $\equiv$ $P_r(obj) * IoU$
  * $P_r(obj)$ is the probability the box contains an object
* conditional class probability $\equiv$ $P_r(class_i|obj)
  * $P_r(class_i|obj) is the probability the object belongs to $class_i$ given an object is presense.
* class confidence score $\equiv$ $P_r(class_i) * IoU = box * confidence score * conditional class probability
  * $P_r(class_i)$ is the probability the object belongs to $class_i$


### Loss Function
YOLO predicts multiple bounding boxes per grid cell. YOLO uses sum-squared error between the predictions and the ground truth to calculate loss. The loss function composes of: the **classification loss**, the **localization loss** (errors between the predicted boundary box and the ground truth), the **confidence loss** (the objectness of the box).



## Reference
* https://pjreddie.com/media/files/papers/YOLOv3.pdf
* https://medium.com/@jonathan_hui/real-time-object-detection-with-yolo-yolov2-28b1b93e2088