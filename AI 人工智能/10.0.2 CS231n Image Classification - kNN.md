# CS231n Image Classification: Data-driven Approach, k-Nearest Neighbor, train/val/test splits

http://cs231n.github.io

* **image classification**
  * 监督学习后，再去预测
* **evaluation** on the actual **test set**
* **Data-driven Approach**
  * relies on first accumulating a *training dataset* of labeled  images
* **The image classification pipeline**
  * input(training images + lables) --> learning --> evaluation
* **L1/L2 distances**
* **hyperparameter search**
* **cross-validation**
  * can help reduce noise in estimating which hyperparameters work best
* **Nearest Neighbor Classifier**
  * there're multiple **hyper-parameters** (such as value of k, or the type of distance used to compare examples)
* Set these hyperparameters: split training data into two: a training set and a **validation set**.

**Image Classification Challenges** A good image classification model must be invariant to the cross product of all these variations, while simultaneously retaining sensitivity to the inter-class variations.

![Image Classification Challenges](https://github.com/AarioAi/Note/blob/master/Image%20Recoginization%20%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/_asset/CS231n-image-classification-challeges.jpg?raw=true)

## Nearset Neighbor Classifier

Nearest Neighbor Classifier has nothing to do with Convolutional Neural Networks, and it's very rarely used in practice.

* Pros:
  * a good choice when the data is low-dimensional
* Cons:
  * not suit for high-dimensional spaces
  * must remember all training data --> inefficient
  * requires a comparion to all training images to classify a test image
  * L1/L2 distances is not adequate

![L2 distance](https://github.com/AarioAi/Note/blob/master/Image%20Recoginization%20%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/_asset/CS231n-L2-distance.png?raw=true)

### L1 (Manhattan) Distance

One of the simplest possibilities is to compare the images pixel by pixel and add up all the differences.

$d_1(I_1,I_2) = \sum_p{|I_1^p - I_2^p|}$

Pixel-wise differences to compare two images with L1 distance (for one color channel)

![L1 Distance](https://github.com/AarioAi/Note/blob/master/Image%20Recoginization%20%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/_asset/CS231n-L1-Distance.jpg?raw=true)

### L2 (Euclidean) Distance

L2 distance has the geometric interpretation of computing the euclidean distance between two vectors.

$d_2(I_1,I_2) = \sqrt{\sum_p(I_1^p - I_2^p)^2}$

## kNN

 Instead of finding the single closest image in the training set, we will find the top k closest images, and have them *vote on the label of the test image*. In particular, when k = 1, we recover the Nearest Neighbor classifier. Intuitively, higher values of k have a smoothing effect that makes the classifier more resistant to outliers:

![kNN](https://github.com/AarioAi/Note/blob/master/Image%20Recoginization%20%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/_asset/CS231n-kNN.jpg?raw=true)

> **Hyperparameters**: We saw that there are many different distance functions we could have used: L1 norm, L2 norm, there are many other choices we didn’t even consider (e.g. dot products). These choices are called hyperparameters.
>> Do not the test set for the purpose of tweaking hyperparameters.
>>> Evaluate on the test set only a single time, at the very end.
>> Split your training set into training set (ps: 49,000 out of a 50,000 images training set) and a **validation set** (ps: 1000 out of a 50,000 images training set). Use validation set to tune all hyperparameters. At the end run a single time on the test set and report performance.

```psucode
accuries = []
for k in [1, 3, 5, 10, 20, 50, 100] {
  nn = NearestNeighbor()
  nn.train(last49000forTrainX, last49000forTrainY)
  predict = nn.predict(first1000forValidationX, k)
  accuracy = np.mean(predict == first1000forValidationY)
  accuries[k] = accuracy
}
```